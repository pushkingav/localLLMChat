## Project Overview

**localLLLMChat** is a Java-based AI chat application designed for privacy, speed, and flexibility. 
It leverages a local Large Language Model (LLM) to provide intelligent conversational capabilities without relying on external cloud services.
It is built as a follow-up to the [Spring AI Course](https://www.udemy.com/course/spring-ai-rag/) on Udemy.

## Key Features

- **Java AI Chat:** Built entirely in Java for seamless integration with enterprise and desktop environments.
- **Powered by Local LLM:** All AI processing is performed locally, ensuring data privacy and low-latency responses.
- **Spring Boot & Spring AI:** Utilizes the robust Spring Boot framework for rapid development and deployment, and integrates with [Spring AI](https://docs.spring.io/spring-ai/reference/) for advanced AI features.

## Getting Started

1. **Clone the Repository:**  
   `git clone <your-repo-url>`

2. **Build the Project:**  
   Use Maven to build the project.

3. **Run the Application:**  
   Start the application using your preferred IDE or via the command line:  
   `mvn spring-boot:run`  

4. **Access the Chat Interface:**  
   Open your browser and navigate to `http://localhost:8080` (or the configured port).

## Documentation

- **Spring Boot Documentation:**  
  [https://docs.spring.io/spring-boot/docs/current/reference/html/](https://docs.spring.io/spring-boot/docs/current/reference/html/)

- **Spring AI Documentation:**  
  [https://docs.spring.io/spring-ai/reference/](https://docs.spring.io/spring-ai/reference/)

## Support

For issues or feature requests, please open an issue in the repository.